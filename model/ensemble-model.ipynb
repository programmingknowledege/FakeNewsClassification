{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1484b158-7bb2-423d-a410-cf21c6f4eba3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import (\n",
    "    RegexTokenizer, Tokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer, HashingTF\n",
    ")  \n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator \n",
    "from pyspark.sql.functions import lit, regexp_replace, lower, explode, col \n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType  \n",
    "from pyspark.ml import PipelineModel \n",
    "from pyspark.ml.tuning import CrossValidator, TrainValidationSplit \n",
    "from pyspark.ml.param.shared import HasSeed \n",
    "from pyspark.ml.util import _jvm  \n",
    "from pyspark.sql.types import ArrayType, StringType  \n",
    "from pyspark.sql.functions import udf \n",
    "from statistics import mode \n",
    "from pyspark.sql.types import DoubleType\n",
    "import pyspark.sql.functions as sql_f\n",
    "\n",
    "# Initialize SparkSession with master node set as local\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"MLlib lab\").getOrCreate()\n",
    "\n",
    "# Get Spark context from Spark session for low-level operations\n",
    "sc = spark.sparkContext\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b47fbf8e-bf07-461c-a027-add80fe8b061",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----+-----+-----+---------+------+\n|               title|                text|date|label|   id|timestamp|source|\n+--------------------+--------------------+----+-----+-----+---------+------+\n|Virginia school b...|A county school b...|NULL|    1|0d7a1|     NULL| kafka|\n|'Don't stay here,...|Police evacuate e...|NULL|    1|0a47a|     NULL| kafka|\n|Woman's convictio...|Bailey Boswell wa...|NULL|    1|06308|     NULL| kafka|\n|Suspected NYC rap...|The New York City...|NULL|    1|07b9e|     NULL| kafka|\n|Hundreds of prote...|Hundreds of prote...|NULL|    1|127e2|     NULL| kafka|\n+--------------------+--------------------+----+-----+-----+---------+------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "#Read fake new data from the delta table\n",
    "fake_news_dataset = spark.read.format(\"delta\").table(\"news_data\")\n",
    "fake_news_dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88551712-1842-4497-8b8d-ecc64e20e89e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['title', 'text', 'date', 'label', 'id', 'timestamp', 'source']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the 'fake_news_dataset' into training and test sets with a ratio of 70% to 30% respectively\n",
    "(training_fake_news_data, test_fake_news_data) = fake_news_dataset.randomSplit([0.7, 0.3], seed=100)\n",
    "\n",
    "#Print the columns\n",
    "columnnames = training_fake_news_data.columns\n",
    "\n",
    "# Print or retrieve the column names\n",
    "columnnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1731a98d-7940-470d-a55c-fdd536e6dd33",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Row(label=0, count=84372), Row(label=1, count=70370)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_counts = training_fake_news_data.groupBy('label').count().orderBy(\"count\", ascending=False)\n",
    "value_counts.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79c8f403-c6c4-4022-9bf9-b5812e639eae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------------------------------------------------------------------------------------------+----+-----+------------------------------------+---------+-------+------------------------------------------------------------------------------------------------------+\n|title|text                                                                                                    |date|label|id                                  |timestamp|source |clean_text                                                                                            |\n+-----+--------------------------------------------------------------------------------------------------------+----+-----+------------------------------------+---------+-------+------------------------------------------------------------------------------------------------------+\n|NULL |\"\"\"Ms Peterson please participate in the voting process of Cuba or China.Thanks\"\"-The Electoral College\"|NULL|1    |95fee8c9-eed9-451b-a7b0-78cec2e25693|NULL     |dataset|\"\"\"ms peterson please participate in the voting process of cuba or chinathanks\"\"the electoral college\"|\n+-----+--------------------------------------------------------------------------------------------------------+----+-----+------------------------------------+---------+-------+------------------------------------------------------------------------------------------------------+\nonly showing top 1 row\n\n"
     ]
    }
   ],
   "source": [
    "global punctuation_chars\n",
    "punctuation_chars = '!#$%&'\n",
    "\n",
    "def preprocessing_fake_news_text_data(dataset, punctuation_chars):\n",
    "    # Convert text to lowercase\n",
    "    dataset = dataset.withColumn('clean_text', lower(dataset['text']))\n",
    "    \n",
    "    # Remove URLs\n",
    "    dataset = dataset.withColumn(\"clean_text\", regexp_replace(dataset[\"clean_text\"], r\"http[s]?\\://\\S+\", \"\")) \n",
    "    \n",
    "    # Remove text within parentheses or square brackets\n",
    "    dataset = dataset.withColumn(\"clean_text\", regexp_replace(dataset[\"clean_text\"], r\"(\\(.*\\))|(\\[.*\\])\", \"\"))\n",
    "    \n",
    "    # Remove words containing consecutive asterisks\n",
    "    dataset = dataset.withColumn(\"clean_text\", regexp_replace(dataset[\"clean_text\"], r\"\\b\\w+\\*{2,3}\\w*\\b\", \"\"))\n",
    "    \n",
    "    # Remove special characters and punctuation\n",
    "    dataset = dataset.withColumn(\"clean_text\", regexp_replace(dataset[\"clean_text\"], r'[!#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}]+', \"\"))\n",
    "    dataset = dataset.withColumn(\"clean_text\", regexp_replace(dataset[\"clean_text\"], r\"[\" + re.escape(punctuation_chars) + \"]\", \"\"))\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "training_fake_news_data = preprocessing_fake_news_text_data(training_fake_news_data,punctuation_chars)\n",
    "training_fake_news_data.show(1,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4ffd67b-1c00-49c3-b42a-7d1296b26e24",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n|label|          clean_text|               words|\n+-----+--------------------+--------------------+\n|    1|\"\"\"ms peterson pl...|[ms, peterson, pl...|\n|    1|\"\"\"ms peterson pl...|[ms, peterson, pl...|\n|    1|\"\"\"russian made\"\"...|[russian, made, i...|\n|    1|  \"\"\"a no brainer\"\"\"|    [a, no, brainer]|\n|    1| \"\"\"allies\"\" cringe\"|    [allies, cringe]|\n+-----+--------------------+--------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Initialize the RegexTokenizer object with configuration to tokenize the 'clean_text' column.\n",
    "\n",
    "regex_tokenizer = RegexTokenizer(inputCol=\"clean_text\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "\n",
    "# Apply the tokenizer to the 'training_fake_news_data' DataFrame to create a new column 'words' \n",
    "\n",
    "training_fake_news_data = regex_tokenizer.transform(training_fake_news_data)\n",
    "\n",
    "# Select and display the first 5 rows of the DataFrame showing the 'label', 'clean_text', and 'words' columns.\n",
    "\n",
    "training_fake_news_data.select('label', 'clean_text', 'words').show(5)\n",
    "\n",
    "# tokenizer.save(\"/mnt/2024-team2/tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e02af8db-0b94-4254-a8e8-08f3e3a43b22",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----+-----+--------------------+---------+-------+--------------------+--------------------+--------------------+\n|title|                text|date|label|                  id|timestamp| source|          clean_text|               words|            filtered|\n+-----+--------------------+----+-----+--------------------+---------+-------+--------------------+--------------------+--------------------+\n| NULL|\"\"\"Ms Peterson pl...|NULL|    1|95fee8c9-eed9-451...|     NULL|dataset|\"\"\"ms peterson pl...|[ms, peterson, pl...|[ms, peterson, pl...|\n| NULL|\"\"\"Ms Peterson pl...|NULL|    1|ae072c62-9775-4c9...|     NULL|dataset|\"\"\"ms peterson pl...|[ms, peterson, pl...|[ms, peterson, pl...|\n| NULL|\"\"\"Russian made\"\"...|NULL|    1|19817f29-2d29-4b5...|     NULL|dataset|\"\"\"russian made\"\"...|[russian, made, i...|[russian, made, i...|\n| NULL|  \"\"\"a no brainer\"\"\"|NULL|    1|5200b8d3-807f-499...|     NULL|dataset|  \"\"\"a no brainer\"\"\"|    [a, no, brainer]|           [brainer]|\n| NULL|\"\"\"allies\"\" cringe.\"|NULL|    1|5140e7ef-10f8-48f...|     NULL|dataset| \"\"\"allies\"\" cringe\"|    [allies, cringe]|    [allies, cringe]|\n| NULL|\"A more appropria...|NULL|    1|cc035ba9-b05f-4a5...|     NULL|dataset|\"a more appropria...|[a, more, appropr...|[appropriate, eup...|\n| NULL|\"Actually it was ...|NULL|    1|51d04cde-679f-46a...|     NULL|dataset|\"actually it was ...|[actually, it, wa...|[actually, pick, ...|\n| NULL|\"Actually it was ...|NULL|    1|ae5348d3-67e8-4b9...|     NULL|dataset|\"actually it was ...|[actually, it, wa...|[actually, pick, ...|\n| NULL|\"Does this mean I...|NULL|    1|05e30361-df2c-4fa...|     NULL|dataset|\"does this mean i...|[does, this, mean...|[mean, im, going,...|\n| NULL|\"The military ind...|NULL|    1|a0c1e71f-a8c5-439...|     NULL|dataset|\"the military ind...|[the, military, i...|[military, indust...|\n+-----+--------------------+----+-----+--------------------+---------+-------+--------------------+--------------------+--------------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "#Instantiate StopwordRemover object that will remove the stopwords from the words\n",
    "stopwords_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "\n",
    "#Apply the tokenizer to the 'training_fake_news_data' DataFrame to create a new column 'words' \n",
    "training_fake_news_data = stopwords_remover.transform(training_fake_news_data)\n",
    "training_fake_news_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faf60801-46c1-4e39-af74-5d82a24ad4b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----+-----+--------------------+---------+-------+--------------------+--------------------+--------------------+--------------------+\n|title|                text|date|label|                  id|timestamp| source|          clean_text|               words|            filtered|        raw_features|\n+-----+--------------------+----+-----+--------------------+---------+-------+--------------------+--------------------+--------------------+--------------------+\n| NULL|\"\"\"Ms Peterson pl...|NULL|    1|95fee8c9-eed9-451...|     NULL|dataset|\"\"\"ms peterson pl...|[ms, peterson, pl...|[ms, peterson, pl...|(3000,[476,1040,1...|\n| NULL|\"\"\"Ms Peterson pl...|NULL|    1|ae072c62-9775-4c9...|     NULL|dataset|\"\"\"ms peterson pl...|[ms, peterson, pl...|[ms, peterson, pl...|(3000,[476,1040,1...|\n| NULL|\"\"\"Russian made\"\"...|NULL|    1|19817f29-2d29-4b5...|     NULL|dataset|\"\"\"russian made\"\"...|[russian, made, i...|[russian, made, i...|(3000,[173,323,42...|\n| NULL|  \"\"\"a no brainer\"\"\"|NULL|    1|5200b8d3-807f-499...|     NULL|dataset|  \"\"\"a no brainer\"\"\"|    [a, no, brainer]|           [brainer]|  (3000,[914],[1.0])|\n| NULL|\"\"\"allies\"\" cringe.\"|NULL|    1|5140e7ef-10f8-48f...|     NULL|dataset| \"\"\"allies\"\" cringe\"|    [allies, cringe]|    [allies, cringe]|(3000,[329,2855],...|\n| NULL|\"A more appropria...|NULL|    1|cc035ba9-b05f-4a5...|     NULL|dataset|\"a more appropria...|[a, more, appropr...|[appropriate, eup...|(3000,[433,538,61...|\n| NULL|\"Actually it was ...|NULL|    1|51d04cde-679f-46a...|     NULL|dataset|\"actually it was ...|[actually, it, wa...|[actually, pick, ...|(3000,[80,366,378...|\n| NULL|\"Actually it was ...|NULL|    1|ae5348d3-67e8-4b9...|     NULL|dataset|\"actually it was ...|[actually, it, wa...|[actually, pick, ...|(3000,[80,366,378...|\n| NULL|\"Does this mean I...|NULL|    1|05e30361-df2c-4fa...|     NULL|dataset|\"does this mean i...|[does, this, mean...|[mean, im, going,...|(3000,[74,217,283...|\n| NULL|\"The military ind...|NULL|    1|a0c1e71f-a8c5-439...|     NULL|dataset|\"the military ind...|[the, military, i...|[military, indust...|(3000,[32,123,188...|\n+-----+--------------------+----+-----+--------------------+---------+-------+--------------------+--------------------+--------------------+--------------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "#Define HashingTF transformer\n",
    "hashing_tf = HashingTF(inputCol=\"filtered\", \n",
    "                       outputCol=\"raw_features\",  \n",
    "                       numFeatures=3000) \n",
    "\n",
    "#Transform the input data using HashingTF\n",
    "featurized_data = hashing_tf.transform(training_fake_news_data)\n",
    "\n",
    "#Show the first 10 rows of the transformed DataFrame\n",
    "featurized_data.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da71675e-8cac-4f48-94ca-40540dc3c89c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----+-----+--------------------+---------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n|title|                text|date|label|                  id|timestamp| source|          clean_text|               words|            filtered|        raw_features|            features|\n+-----+--------------------+----+-----+--------------------+---------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n| NULL|\"\"\"Ms Peterson pl...|NULL|    1|95fee8c9-eed9-451...|     NULL|dataset|\"\"\"ms peterson pl...|[ms, peterson, pl...|[ms, peterson, pl...|(3000,[476,1040,1...|(3000,[476,1040,1...|\n| NULL|\"\"\"Ms Peterson pl...|NULL|    1|ae072c62-9775-4c9...|     NULL|dataset|\"\"\"ms peterson pl...|[ms, peterson, pl...|[ms, peterson, pl...|(3000,[476,1040,1...|(3000,[476,1040,1...|\n| NULL|\"\"\"Russian made\"\"...|NULL|    1|19817f29-2d29-4b5...|     NULL|dataset|\"\"\"russian made\"\"...|[russian, made, i...|[russian, made, i...|(3000,[173,323,42...|(3000,[173,323,42...|\n| NULL|  \"\"\"a no brainer\"\"\"|NULL|    1|5200b8d3-807f-499...|     NULL|dataset|  \"\"\"a no brainer\"\"\"|    [a, no, brainer]|           [brainer]|  (3000,[914],[1.0])|(3000,[914],[3.61...|\n| NULL|\"\"\"allies\"\" cringe.\"|NULL|    1|5140e7ef-10f8-48f...|     NULL|dataset| \"\"\"allies\"\" cringe\"|    [allies, cringe]|    [allies, cringe]|(3000,[329,2855],...|(3000,[329,2855],...|\n| NULL|\"A more appropria...|NULL|    1|cc035ba9-b05f-4a5...|     NULL|dataset|\"a more appropria...|[a, more, appropr...|[appropriate, eup...|(3000,[433,538,61...|(3000,[433,538,61...|\n| NULL|\"Actually it was ...|NULL|    1|51d04cde-679f-46a...|     NULL|dataset|\"actually it was ...|[actually, it, wa...|[actually, pick, ...|(3000,[80,366,378...|(3000,[80,366,378...|\n| NULL|\"Actually it was ...|NULL|    1|ae5348d3-67e8-4b9...|     NULL|dataset|\"actually it was ...|[actually, it, wa...|[actually, pick, ...|(3000,[80,366,378...|(3000,[80,366,378...|\n| NULL|\"Does this mean I...|NULL|    1|05e30361-df2c-4fa...|     NULL|dataset|\"does this mean i...|[does, this, mean...|[mean, im, going,...|(3000,[74,217,283...|(3000,[74,217,283...|\n| NULL|\"The military ind...|NULL|    1|a0c1e71f-a8c5-439...|     NULL|dataset|\"the military ind...|[the, military, i...|[military, indust...|(3000,[32,123,188...|(3000,[32,123,188...|\n+-----+--------------------+----+-----+--------------------+---------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "#Create IDF transformer object\n",
    "idf = IDF(inputCol=\"raw_features\",\n",
    "          outputCol=\"features\")\n",
    "\n",
    "#Fit IDF transformer to the featurized data\n",
    "idf_vectorizer = idf.fit(featurized_data)\n",
    "\n",
    "#Transform the featurized data using the trained IDF model\n",
    "rescaled_data = idf_vectorizer.transform(featurized_data)\n",
    "\n",
    "#displayed  the first 10 rows of the transformed DataFrame\n",
    "rescaled_data.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66755ac1-94bf-43e1-89f4-c8eacba5db61",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression_05aaec992716"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Created the logistic regression object\n",
    "lr_model=LogisticRegression()\n",
    "lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bc6597b-003c-44ce-9b0d-b5d5062d54ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "models=[]\n",
    "def bagging(trainingData, weak_learner,bootstrap_size,max_iter=10): \n",
    "  '''Create the bagging function that will create multiple classifier'''\n",
    "  for iteration in range(max_iter): \n",
    "    bag=trainingData.sample(withReplacement=True,fraction=1.0)\n",
    "    lr_model.setPredictionCol(f\"prediction_{iteration}\")\n",
    "    lr_model.setProbabilityCol(f\"probability_{iteration}\")\n",
    "    lr_model.setRawPredictionCol(f\"rawPrediction_{iteration}\")\n",
    "    models.append(lr_model.fit(trainingData))\n",
    "max_iter=10\n",
    "bagging(rescaled_data,lr_model,1,max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fa919cd-2019-42a2-834b-b009d199f1da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Created the multi class evaluator object\n",
    "evaluator=MulticlassClassificationEvaluator(labelCol='label',metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35f92cea-9a56-4bb5-a3ae-12003b2b64a0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n|                text|label|          clean_text|               words|            filtered|        raw_features|            features|\n+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n|\"\"\"Russian made\"\"...|    1|\"\"\"russian made\"\"...|[russian, made, i...|[russian, made, i...|(3000,[173,323,42...|(3000,[173,323,42...|\n|\"Parts 5 & 6 Obel...|    1|\"parts 5  6 obeli...|[parts, 5, 6, obe...|[parts, 5, 6, obe...|(3000,[154,708,18...|(3000,[154,708,18...|\n|\"Stock \"\"On Fire!\"\"\"|    1| \"stock \"\"on fire\"\"\"|   [stock, on, fire]|       [stock, fire]|(3000,[191,1793],...|(3000,[191,1793],...|\n|\"There's no quest...|    1|\"theres no questi...|[theres, no, ques...|[theres, question...|(3000,[306,357,42...|(3000,[306,357,42...|\n|\"They aren't spen...|    1|\"they arent spend...|[they, arent, spe...|[arent, spending,...|(3000,[79,660,958...|(3000,[79,660,958...|\n|\"When we leave th...|    1|\"when we leave th...|[when, we, leave,...|[leave, philippin...|(3000,[62,103,173...|(3000,[62,103,173...|\n|\"makes me think o...|    1|\"makes me think o...|[makes, me, think...|[makes, think, pe...|(3000,[335,1830,1...|(3000,[335,1830,1...|\n|... and this is h...|    1| and this is how ...|[and, this, is, h...|[gov, smash, expe...|(3000,[158,826,88...|(3000,[158,826,88...|\n|A big selloff int...|    1|a big selloff int...|[a, big, selloff,...|[big, selloff, el...|(3000,[27,61,100,...|(3000,[27,61,100,...|\n|Agreed. The ingre...|    1|agreed the ingred...|[agreed, the, ing...|[agreed, ingredie...|(3000,[103,742,10...|(3000,[103,742,10...|\n|Agreed. The ingre...|    1|agreed the ingred...|[agreed, the, ing...|[agreed, ingredie...|(3000,[103,742,10...|(3000,[103,742,10...|\n|All day send that...|    1|all day send that...|[all, day, send, ...|[day, send, shit,...|(3000,[1460,2133,...|(3000,[1460,2133,...|\n|All eyes on Elect...|    1|all eyes on elect...|[all, eyes, on, e...|[eyes, electoral,...|(3000,[858,1289,1...|(3000,[858,1289,1...|\n|All forms of reli...|    1|all forms of reli...|[all, forms, of, ...|[forms, religion,...|(3000,[350,619,86...|(3000,[350,619,86...|\n|Although I may di...|    1|although i may di...|[although, i, may...|[although, may, d...|(3000,[15,160,184...|(3000,[15,160,184...|\n|Another example o...|    1|another example o...|[another, example...|[another, example...|(3000,[191,417,60...|(3000,[191,417,60...|\n|As I told my teen...|    1|as i told my teen...|[as, i, told, my,...|[told, teenage, d...|(3000,[23,193,306...|(3000,[23,193,306...|\n|Beard or no beard...|    1|beard or no beard...|[beard, or, no, b...|[beard, beard, sp...|(3000,[918,1300,1...|(3000,[918,1300,1...|\n|Before you start ...|    1|before you start ...|[before, you, sta...|[start, complaini...|(3000,[163,360,44...|(3000,[163,360,44...|\n|     Boycott the NFL|    1|     boycott the nfl| [boycott, the, nfl]|      [boycott, nfl]|(3000,[35,2034],[...|(3000,[35,2034],[...|\n+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "def test_models(test_features,models): \n",
    "  'Created the test function to test the bagging model on test data '\n",
    "  for model in range(0,len(models)): \n",
    "    prediction=models[model].transform(test_features)\n",
    "    evaluator.setPredictionCol(f'prediction_{model}')\n",
    "    acc=evaluator.evaluate(prediction)\n",
    "    print(f'accuracy {model}:{acc}')\n",
    "\n",
    "test_fake_news_data=test_fake_news_data.select('text','label')    \n",
    "test_fake_news_data = preprocessing_fake_news_text_data(test_fake_news_data,punctuation_chars)\n",
    "# trainingData.show(1,truncate=False)\n",
    "test_fake_news_data = regex_tokenizer.transform(test_fake_news_data)\n",
    "# Remove stopwords\n",
    "test_fake_news_data = stopwords_remover.transform(test_fake_news_data)\n",
    "# Convert text to features\n",
    "test_fake_news_data = hashing_tf.transform(test_fake_news_data)\n",
    "# Apply IDF\n",
    "test_fake_news_data = idf_vectorizer.transform(test_fake_news_data)\n",
    "test_fake_news_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "049b33fe-403d-4ff2-93f6-b197fcd6f084",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0:0.723986063558619\naccuracy 1:0.723986063558619\naccuracy 2:0.723986063558619\naccuracy 3:0.723986063558619\naccuracy 4:0.723986063558619\naccuracy 5:0.723986063558619\naccuracy 6:0.723986063558619\naccuracy 7:0.723986063558619\naccuracy 8:0.723986063558619\naccuracy 9:0.723986063558619\n"
     ]
    }
   ],
   "source": [
    "models\n",
    "test_models(test_fake_news_data,models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "539fb28e-282c-4823-8c2f-fa058f663218",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pipeline_models=PipelineModel(stages=models)\n",
    "prediction=pipeline_models.transform(test_fake_news_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "275a10c6-b60d-4b44-aa04-5c8bdc2847a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n|               preds|label|\n+--------------------+-----+\n|[1.0, 1.0, 1.0, 1...|    1|\n+--------------------+-----+\nonly showing top 1 row\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ensemble=prediction.select(sql_f.array([f\"prediction_{i}\" for i in range(max_iter)]).alias('preds'), 'label')\n",
    "ensemble.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14bf7f0f-54c4-4a93-a02c-597e4df9fb9e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n|               preds|label|prediction|\n+--------------------+-----+----------+\n|[1.0, 1.0, 1.0, 1...|    1|       1.0|\n|[1.0, 1.0, 1.0, 1...|    1|       1.0|\n|[1.0, 1.0, 1.0, 1...|    1|       1.0|\n|[1.0, 1.0, 1.0, 1...|    1|       1.0|\n|[1.0, 1.0, 1.0, 1...|    1|       1.0|\n|[1.0, 1.0, 1.0, 1...|    1|       1.0|\n|[1.0, 1.0, 1.0, 1...|    1|       1.0|\n|[1.0, 1.0, 1.0, 1...|    1|       1.0|\n|[1.0, 1.0, 1.0, 1...|    1|       1.0|\n|[1.0, 1.0, 1.0, 1...|    1|       1.0|\n|[1.0, 1.0, 1.0, 1...|    1|       1.0|\n|[1.0, 1.0, 1.0, 1...|    1|       1.0|\n|[1.0, 1.0, 1.0, 1...|    1|       1.0|\n|[0.0, 0.0, 0.0, 0...|    1|       0.0|\n|[0.0, 0.0, 0.0, 0...|    1|       0.0|\n|[1.0, 1.0, 1.0, 1...|    1|       1.0|\n|[0.0, 0.0, 0.0, 0...|    1|       0.0|\n|[1.0, 1.0, 1.0, 1...|    1|       1.0|\n|[1.0, 1.0, 1.0, 1...|    1|       1.0|\n|[1.0, 1.0, 1.0, 1...|    1|       1.0|\n+--------------------+-----+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mode_udf=sql_f.udf(mode,DoubleType())\n",
    "prediction=ensemble.withColumn('prediction',mode_udf('preds'))\n",
    "prediction.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b238c53f-3811-463b-a5c8-80fb4a67476c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.723986063558619\nPrecision: 0.7235523716273575\nRecall: 0.723986063558619\nF1 Score: 0.7236984691317211\n"
     ]
    }
   ],
   "source": [
    "#Calculate evaluation metrics \n",
    "evaluator.setPredictionCol('prediction')\n",
    "evaluator.evaluate(prediction)\n",
    "accuracy = evaluator.evaluate(prediction, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(prediction, {evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = evaluator.evaluate(prediction, {evaluator.metricName: \"weightedRecall\"})\n",
    "f1_score = evaluator.evaluate(prediction, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "# Print the confusion metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88d3d546-2060-475f-a991-423f7fdd13b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "ensemble-model",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
